{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el conjunto de datos MNIST para la demostración de cómo guardar y cargar pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation = 'relu', input_shape = (784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "                  metrics = [tf.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos puntos de control durante el entrenamiento.\n",
    "\n",
    "Podemos usar un modelo entrenado sin tener que volver a entrenarlo o retomar el entrenamiento donde lo dejamos en caso de que se interrumpa el proceso de entrenamiento. La callback tf.keras.callbacks.ModelCheckpoint nos permite guardar continuamente el modelo durante y al final del entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una callback que guarde los pesos SOLO durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "Epoch 1/10\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 1.2052 - sparse_categorical_accuracy: 0.6540\n",
      "Epoch 1: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 2s 22ms/step - loss: 1.1492 - sparse_categorical_accuracy: 0.6700 - val_loss: 0.7207 - val_sparse_categorical_accuracy: 0.7790\n",
      "Epoch 2/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.4451 - sparse_categorical_accuracy: 0.8739\n",
      "Epoch 2: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.4383 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.5483 - val_sparse_categorical_accuracy: 0.8330\n",
      "Epoch 3/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.2977 - sparse_categorical_accuracy: 0.9224\n",
      "Epoch 3: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.2976 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.4997 - val_sparse_categorical_accuracy: 0.8430\n",
      "Epoch 4/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.2152 - sparse_categorical_accuracy: 0.9491\n",
      "Epoch 4: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.2097 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.8490\n",
      "Epoch 5/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.1592 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 5: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1570 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8460\n",
      "Epoch 6/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.1176 - sparse_categorical_accuracy: 0.9752\n",
      "Epoch 6: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.4227 - val_sparse_categorical_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.0895 - sparse_categorical_accuracy: 0.9873\n",
      "Epoch 7: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.0643 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 8: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.4033 - val_sparse_categorical_accuracy: 0.8690\n",
      "Epoch 9/10\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.0528 - sparse_categorical_accuracy: 0.9978\n",
      "Epoch 9: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.4306 - val_sparse_categorical_accuracy: 0.8560\n",
      "Epoch 10/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.0411 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 10: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4233 - val_sparse_categorical_accuracy: 0.8620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22682453750>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'training_1/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Creamos una callback que guarde los pesos del modelo.\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                 save_weights_only = True,\n",
    "                                                 verbose = 1)\n",
    "\n",
    "# Entrenamos el modelo con el callback.\n",
    "model.fit(train_images,\n",
    "          train_labels,\n",
    "          epochs = 10,\n",
    "          validation_data = (test_images, test_labels),\n",
    "          callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto crea una única colección de archivos de puntos de control de Tensorflow que se actualiza al final de cada época:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint', 'cp.ckpt.data-00000-of-00001', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre que dos modelos compartan la misma arquitectura, pueden compartir pesos entre ellos. Por lo tanto, cuando restauremos un modelo de solo pesos, creamos un modelo con la misma arquitectura que el modelo original y luego establecemos sus pesos.\n",
    "\n",
    "Ahora vamos a reconstruir un modelo nuevo, no entrenado y lo evaluamos con el conjunto de prueba. Un modelo no entrenado se desempeñará en nivelos de probabilidad(~10 % de precisión):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo básico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.4001 - sparse_categorical_accuracy: 0.0520 - 362ms/epoch - 11ms/step\n",
      "Modelo no entrenado, accuracy:  5.20%\n"
     ]
    }
   ],
   "source": [
    "model_2 = create_model()\n",
    "\n",
    "# Evaluamos el modelo.\n",
    "loss, acc = model_2.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('Modelo no entrenado, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los pesos desde el checkpoint y volvemos a evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4233 - sparse_categorical_accuracy: 0.8620 - 107ms/epoch - 3ms/step\n",
      "Modelo con pesos agregados, accuracy: 86.20%\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los pesos.\n",
    "model_2.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluamos el modelo.\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('Modelo con pesos agregados, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las callbacks ofrecen varias opciones para proporcionar nombres únicos para los checkpoints y ajustar la frecuencia de los puntos de control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un modelo y guardamos los checkpoints con nombres exclusivos una vez cada cinco épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: saving model to training_2\\cp-0005.ckpt\n",
      "\n",
      "Epoch 10: saving model to training_2\\cp-0010.ckpt\n",
      "\n",
      "Epoch 15: saving model to training_2\\cp-0015.ckpt\n",
      "\n",
      "Epoch 20: saving model to training_2\\cp-0020.ckpt\n",
      "\n",
      "Epoch 25: saving model to training_2\\cp-0025.ckpt\n",
      "\n",
      "Epoch 30: saving model to training_2\\cp-0030.ckpt\n",
      "\n",
      "Epoch 35: saving model to training_2\\cp-0035.ckpt\n",
      "\n",
      "Epoch 40: saving model to training_2\\cp-0040.ckpt\n",
      "\n",
      "Epoch 45: saving model to training_2\\cp-0045.ckpt\n",
      "\n",
      "Epoch 50: saving model to training_2\\cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268317cd50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incluimos la epoca en el nombre del archivo.\n",
    "checkpoint_path = 'training_2/cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Creamos un callback que guarde los pesos del modelo cada 5 épocas.\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    verbose = 1,\n",
    "    save_weights_only = True,\n",
    "    save_freq = 5 * batch_size\n",
    ")\n",
    "\n",
    "model_3 = create_model()\n",
    "\n",
    "model_3.save_weights(checkpoint_path.format(epoch = 0))\n",
    "\n",
    "model_3.fit(train_images,\n",
    "            train_labels,\n",
    "            epochs = 50,\n",
    "            batch_size = batch_size,\n",
    "            callbacks = [cp_callback],\n",
    "            validation_data = (test_images, test_labels),\n",
    "            verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los checkpoints y elegimos el último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index',\n",
       " 'cp-0025.ckpt.data-00000-of-00001',\n",
       " 'cp-0025.ckpt.index',\n",
       " 'cp-0030.ckpt.data-00000-of-00001',\n",
       " 'cp-0030.ckpt.index',\n",
       " 'cp-0035.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.index',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.index',\n",
       " 'cp-0045.ckpt.data-00000-of-00001',\n",
       " 'cp-0045.ckpt.index',\n",
       " 'cp-0050.ckpt.data-00000-of-00001',\n",
       " 'cp-0050.ckpt.index']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar, reiniciamos el modelo y cargamos el último punto de control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4727 - sparse_categorical_accuracy: 0.8760 - 403ms/epoch - 13ms/step\n",
      "Modelo con pesos agregados versión 2, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "model_4 = create_model()\n",
    "\n",
    "model_4.load_weights(latest)\n",
    "\n",
    "loss, acc = model_4.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('Modelo con pesos agregados versión 2, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior almacena los pesos en una colección de archivos con formato de checkpoints que contienen solo los pesos entrenados en un formato binario. Los checkpoints contienen:\n",
    "\n",
    "* Uno o más fragmentos que contienen los pesos de su modelo.\n",
    "* Un archivo de índice que indica qué pesos se almacenan en qué fragmento.\n",
    "\n",
    "Si entrenamos un modelo en una sola máquina, tendremos un fragmento con el sufijo: .data-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos pesos manualmente.\n",
    "\n",
    "Con el método Model.save_weights vamos a guardar los pesos manualmente. De forma predeterminada, tf.keras y save_weights en particular, usa el formato de checkpoint de Tensorflow con una extensión .ckpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4727 - sparse_categorical_accuracy: 0.8760 - 341ms/epoch - 11ms/step\n",
      "Modelo con pesos agregados versión 3, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "model_4.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "model_4 = create_model()\n",
    "\n",
    "model_4.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss, acc = model_4.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('Modelo con pesos agregados versión 3, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar todo el modelo.\n",
    "\n",
    "Llamamos a model.save para guardar la arquitectura, los pesos y la configuración de entrenamiento de un modelo en un solo archivo/carpeta. Esto permite exporta un modelo para que pueda usarse sin acceso al código original de Python. Dado que se recuper ael estadoo de optimizador, puede reanudar el entrenamiento exactamente desde lo dejamos.\n",
    "\n",
    "Un modelo completo se puede guardar en dos formatos de archivo diferentes (SavedModel y HDF5). El formato de SavedModel de TensorFlow es el formato de archivo predeterminado en TF2.x. Sin embargo, los modelos se pueden guardar en formato HDF5.\n",
    "\n",
    "Guardar un modelo completamente funcional es muy útil: podemos cargarlo en TensorFlow.js (SavedModel, HDF5) y luego entrenarlo y ejecutarlo en navegadores web, o convertirlo para ejecutarlo en dispositivos móviles usando TensorFlow Lite (SavedModel, HDF5).\n",
    "\n",
    "Los objetos personalizados (p. ej., modelos o capas subclasificados) requieren una atención especial al guardarlos y cargarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formato de modelo guardado.\n",
    "\n",
    "El formato de modelo guardado es otra forma de serializar modelos. Los modelos guardados en este formato se pueden restaurar usando tf.keras.models.load_model y son compatibles con Tensorflow Serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 1.1343 - sparse_categorical_accuracy: 0.6810\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4262 - sparse_categorical_accuracy: 0.8840\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.9270\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2105 - sparse_categorical_accuracy: 0.9480\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1496 - sparse_categorical_accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_5 = create_model()\n",
    "model_5.fit(train_images, train_labels, epochs = 5)\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model_5.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato del modelo es un directorio que contiene un binario protofub y un checkpoint de Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos un modelo nuevo desde el modelo guardado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo restaurado se compila con los mismos argumentos que el modelo original. Probemos evaluar y predecir con el modelo cargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4403 - sparse_categorical_accuracy: 0.8620 - 470ms/epoch - 15ms/step\n",
      "Modelo con pesos agregados versión 4, accuracy: 86.20%\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('Modelo con pesos agregados versión 4, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formato HDF5\n",
    "\n",
    "Keras proporciona un formato de guardado básico utilizando el estándar HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 2s 15ms/step - loss: 1.1354 - sparse_categorical_accuracy: 0.6840\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2811 - sparse_categorical_accuracy: 0.9240\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.2066 - sparse_categorical_accuracy: 0.9520\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1613 - sparse_categorical_accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "model_6 = create_model()\n",
    "model_6.fit(train_images, train_labels, epochs = 5)\n",
    "\n",
    "model_6.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, creamos el modelo con ese archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model_2 = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "new_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 1s - loss: 0.4399 - sparse_categorical_accuracy: 0.8660 - 712ms/epoch - 22ms/step\n",
      "Modelo con pesos agregados versión 5, accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model_2.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('Modelo con pesos agregados versión 5, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras guarda modelos al inspeccionar sus arquitecturas. Esta técnica guarda todo:\n",
    "\n",
    "* Los valores de peso.\n",
    "* La arquitectura del modelo.\n",
    "* La configuración de entrenamiento del modelo (lo que pasa al método .compile()).\n",
    "* El optimizador y su estado, si lo hay (esto le permite reiniciar el entrenamiento donde lo dejó).\n",
    "\n",
    "Keras no puede guardar los optimizadores v1.x (de tf.compat.v1.train ) ya que no son compatibles con los puntos de control. Para los optimizadores v1.x, deberíamos volver a compilar el modelo después de cargarlo, perdiendo el estado del optimizador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia clave entre HDF5 y SavedModel es que HDF5 usa configuraciones de objetos para guardar la arquitectura del modelo, mientras que SavedModel guarda el gráfico de ejecución. Por lo tanto, los modelos guardados pueden guardar objetos personalizados, como modelos subclasificados y capas personalizadas, sin necesidad del código original.\n",
    "\n",
    "Para guardar objetos personalizados en HDF5, debemos hacer lo siguiente:\n",
    "\n",
    "1. Definir un método get_config en su objeto y, opcionalmente, un método de from_config. \n",
    "\n",
    "* get_config(self) devuelve un diccionario serializable JSON de parámetros necesarios para recrear el objeto.  \n",
    "\n",
    "* from_config(cls, config) usa la configuración devuelta de get_config para crear un nuevo objeto. De forma predeterminada, esta función utilizará la configuración como kwargs de inicialización (return cls(**config)).\n",
    "\n",
    "2. Pasemos el objeto al argumento custom_objects al cargar el modelo. El argumento debe ser un diccionario que mapee el nombre de la clase de cadena a la clase de Python. Por ejemplo tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
