{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Tuner es una biblioteca que nos ayuda a elegir el conjunto óptimo de hiperparámetros para nuestro programa TensorFlow. El proceso de seleccionar el conjunto correcto de hiperparámetros para su aplicación de aprendizaje automático (ML) se denomina ajuste de hiperparámetros o hypertuning.\n",
    "\n",
    "Los hiperparámetros son las variables que gobiernan el proceso de entrenamiento y la topología de un modelo de ML. Estas variables permanecen constantes durante el proceso de capacitación e impactan directamente en el rendimiento del programa ML. Los hiperparámetros son de dos tipos:\n",
    "\n",
    "1. Hiperparámetros del modelo que influyen en la selección del modelo, como el número y el ancho de las capas ocultas.\n",
    "\n",
    "2. Hiperparámetros del algoritmo que influyen en la velocidad y la calidad del algoritmo de aprendizaje, como la tasa de aprendizaje para el descenso de gradiente estocástico (SGD) y el número de vecinos más cercanos para un clasificador de vecinos más cercanos (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos Keras Tuner para realizar un hiperajuste para una aplicación de clasificación de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar Keras Tuner para encontrar los mejores hiperparámetros para un modelo de ML que clasifica imágenes de ropa del conjunto de datos Fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los pixeles entre 0 y 1.\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo.\n",
    "\n",
    "Creamos un modelo para hiperajueste, también definimos el espacio de búsqueda de hiperparámetros además de la arquitectura del modelo. El modelo que configuramos para el hiperajuste se denomina hipermodelo.\n",
    "\n",
    "Podemos definir un hipermodelo a través de dos enfoques:\n",
    "\n",
    "* Mediante el uso de una función de generador de modelos.\n",
    "\n",
    "* HyperModel. La clase HyperModel de la API Keras Tuner.\n",
    "\n",
    "También podemos usar dos clases de HyperModel predefinidas: HyperXception e HyperResNet para aplicaciones de visión artificial.\n",
    "\n",
    "Usaremos una función generador de modelos para definir el modelo de clasificación de imágenes. La función del generador de modelos devuelve un modelo compilado y usa hiperparámetros que usted define en línea para hiperafinar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "\n",
    "    # Ajustamos el número de unidades en la primera capa densa.\n",
    "    # Elegimos un valor óptimo entre 32 - 512\n",
    "    hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "    model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Ajustamos la tasa de aprendizaje para el optimizador.\n",
    "    # Elegimos un valor óptimo entre 0,01, 0,001 o 0,0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                  loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos una instancia de sintonizador y realizamos un hiperajuste.\n",
    "\n",
    "Creemos una instancia del sintonizador para realizar el hiperajuste. Keras Tuner tiene cuatro sintonizadores disponibles: RandomSearch, Hyperband, BayesianOptimizer y Sklearn. Vamos a utilizar Hyperband."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instanciar el sintonizador Hyperband, debemos especificar el hipermodelo, el objetive a optimizar y el número máximo de épocas para entrenar(max_epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy',\n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de sintonización Hyperband utiliza la asignación de recursos adaptable y la detención anticipada para converger rápidamente en un modelo de alto rendimiento. Esto se hace usando un soporte estilo campeonato deportivo. El algoritmo entrena una gran cantidad de modelos durante algunas épocas y lleva adelante solo la mitad de los modelos con el mejor rendimientos a la siguiente ronda. Hyperband determina la cantidad de modelos para entrenar en un grupo calculando 1 + factor logarítmico(max_epochs) y redondeándolo al entero más cercano.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creemos una callback para parar el entrenamiento antes de alcanzar cierto valor para la pérdida de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la búsqueda de hiperparametros. Los argumentos para el método de búsqueda son los mismos que los utilizados para tf.keras.model.fit además de la callback anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 15s]\n",
      "val_accuracy: 0.8755000233650208\n",
      "\n",
      "Best val_accuracy So Far: 0.8949999809265137\n",
      "Total elapsed time: 00h 20m 19s\n",
      "\n",
      "    La busqueda de hiperparámetros está completa. El número óptimo de unidades en la primera zona densamente\n",
      "    conectada. La capa 320 y la tasa de aprendizaje óptima para el optmiziador es \n",
      "    0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs = 50, validation_split = 0.2, callbacks = [stop_early])\n",
    "\n",
    "# Obtenemos el hiperparámetro óptimo.\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "    La busqueda de hiperparámetros está completa. El número óptimo de unidades en la primera zona densamente\n",
    "    conectada. La capa {best_hps.get('units')} y la tasa de aprendizaje óptima para el optmiziador es \n",
    "    {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo.\n",
    "\n",
    "Encontremos el número óptimo de épocas para entrenar el modelo con los hiperparámetros obtenidos de la búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.4954 - accuracy: 0.8235 - val_loss: 0.4440 - val_accuracy: 0.8340\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3737 - accuracy: 0.8649 - val_loss: 0.4075 - val_accuracy: 0.8551\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3317 - accuracy: 0.8779 - val_loss: 0.3354 - val_accuracy: 0.8786\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3058 - accuracy: 0.8854 - val_loss: 0.3577 - val_accuracy: 0.8718\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2876 - accuracy: 0.8934 - val_loss: 0.3433 - val_accuracy: 0.8772\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2725 - accuracy: 0.8980 - val_loss: 0.3205 - val_accuracy: 0.8835\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2577 - accuracy: 0.9043 - val_loss: 0.3304 - val_accuracy: 0.8840\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2460 - accuracy: 0.9099 - val_loss: 0.3271 - val_accuracy: 0.8871\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2368 - accuracy: 0.9114 - val_loss: 0.3176 - val_accuracy: 0.8895\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2265 - accuracy: 0.9143 - val_loss: 0.3141 - val_accuracy: 0.8924\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2209 - accuracy: 0.9168 - val_loss: 0.3328 - val_accuracy: 0.8862\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2094 - accuracy: 0.9214 - val_loss: 0.3404 - val_accuracy: 0.8842\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2039 - accuracy: 0.9230 - val_loss: 0.3238 - val_accuracy: 0.8916\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1956 - accuracy: 0.9264 - val_loss: 0.3465 - val_accuracy: 0.8882\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1900 - accuracy: 0.9283 - val_loss: 0.3518 - val_accuracy: 0.8856\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1820 - accuracy: 0.9322 - val_loss: 0.3343 - val_accuracy: 0.8902\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1747 - accuracy: 0.9348 - val_loss: 0.3515 - val_accuracy: 0.8926\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1711 - accuracy: 0.9344 - val_loss: 0.3330 - val_accuracy: 0.8932\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1660 - accuracy: 0.9379 - val_loss: 0.3383 - val_accuracy: 0.8913\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1603 - accuracy: 0.9397 - val_loss: 0.3642 - val_accuracy: 0.8853\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1531 - accuracy: 0.9422 - val_loss: 0.3738 - val_accuracy: 0.8941\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1485 - accuracy: 0.9438 - val_loss: 0.3803 - val_accuracy: 0.8899\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1450 - accuracy: 0.9465 - val_loss: 0.3677 - val_accuracy: 0.8948\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1411 - accuracy: 0.9465 - val_loss: 0.3736 - val_accuracy: 0.8926\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1380 - accuracy: 0.9471 - val_loss: 0.3759 - val_accuracy: 0.8881\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1305 - accuracy: 0.9510 - val_loss: 0.3995 - val_accuracy: 0.8909\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1310 - accuracy: 0.9504 - val_loss: 0.3890 - val_accuracy: 0.8887\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1235 - accuracy: 0.9537 - val_loss: 0.3869 - val_accuracy: 0.8946\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1255 - accuracy: 0.9520 - val_loss: 0.4089 - val_accuracy: 0.8934\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1206 - accuracy: 0.9552 - val_loss: 0.4101 - val_accuracy: 0.8956\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1152 - accuracy: 0.9565 - val_loss: 0.4444 - val_accuracy: 0.8892\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1148 - accuracy: 0.9569 - val_loss: 0.4247 - val_accuracy: 0.8924\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1097 - accuracy: 0.9587 - val_loss: 0.4154 - val_accuracy: 0.8955\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1078 - accuracy: 0.9592 - val_loss: 0.4310 - val_accuracy: 0.8945\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1052 - accuracy: 0.9600 - val_loss: 0.4363 - val_accuracy: 0.8938\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0997 - accuracy: 0.9627 - val_loss: 0.4968 - val_accuracy: 0.8819\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1043 - accuracy: 0.9607 - val_loss: 0.4803 - val_accuracy: 0.8867\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9638 - val_loss: 0.4805 - val_accuracy: 0.8861\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0978 - accuracy: 0.9632 - val_loss: 0.4516 - val_accuracy: 0.8947\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0944 - accuracy: 0.9642 - val_loss: 0.4575 - val_accuracy: 0.8915\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0920 - accuracy: 0.9654 - val_loss: 0.4805 - val_accuracy: 0.8932\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0876 - accuracy: 0.9670 - val_loss: 0.4737 - val_accuracy: 0.8965\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0901 - accuracy: 0.9665 - val_loss: 0.5080 - val_accuracy: 0.8905\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0846 - accuracy: 0.9690 - val_loss: 0.4964 - val_accuracy: 0.8934\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0834 - accuracy: 0.9687 - val_loss: 0.4747 - val_accuracy: 0.8964\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0855 - accuracy: 0.9679 - val_loss: 0.4945 - val_accuracy: 0.8954\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0812 - accuracy: 0.9685 - val_loss: 0.5279 - val_accuracy: 0.8885\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0810 - accuracy: 0.9701 - val_loss: 0.5231 - val_accuracy: 0.8903\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0756 - accuracy: 0.9713 - val_loss: 0.5331 - val_accuracy: 0.8901\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0762 - accuracy: 0.9711 - val_loss: 0.5726 - val_accuracy: 0.8882\n",
      "Mejor época: 42\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs = 50, validation_split = 0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Mejor época: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos a crear instancias del hipermodelo y entrenemos con el número óptimo de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.4958 - accuracy: 0.8246 - val_loss: 0.3931 - val_accuracy: 0.8636\n",
      "Epoch 2/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3719 - accuracy: 0.8649 - val_loss: 0.3933 - val_accuracy: 0.8580\n",
      "Epoch 3/42\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3337 - accuracy: 0.8770 - val_loss: 0.3466 - val_accuracy: 0.8770\n",
      "Epoch 4/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3075 - accuracy: 0.8865 - val_loss: 0.3273 - val_accuracy: 0.8865\n",
      "Epoch 5/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2873 - accuracy: 0.8924 - val_loss: 0.3455 - val_accuracy: 0.8787\n",
      "Epoch 6/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2715 - accuracy: 0.8979 - val_loss: 0.3316 - val_accuracy: 0.8827\n",
      "Epoch 7/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2588 - accuracy: 0.9036 - val_loss: 0.3482 - val_accuracy: 0.8733\n",
      "Epoch 8/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2458 - accuracy: 0.9065 - val_loss: 0.3112 - val_accuracy: 0.8923\n",
      "Epoch 9/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2354 - accuracy: 0.9124 - val_loss: 0.3338 - val_accuracy: 0.8839\n",
      "Epoch 10/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2237 - accuracy: 0.9161 - val_loss: 0.3310 - val_accuracy: 0.8867\n",
      "Epoch 11/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2176 - accuracy: 0.9180 - val_loss: 0.3190 - val_accuracy: 0.8888\n",
      "Epoch 12/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2101 - accuracy: 0.9200 - val_loss: 0.3229 - val_accuracy: 0.8932\n",
      "Epoch 13/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1999 - accuracy: 0.9243 - val_loss: 0.3265 - val_accuracy: 0.8892\n",
      "Epoch 14/42\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1941 - accuracy: 0.9277 - val_loss: 0.3262 - val_accuracy: 0.8942\n",
      "Epoch 15/42\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1878 - accuracy: 0.9296 - val_loss: 0.3273 - val_accuracy: 0.8940\n",
      "Epoch 16/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1807 - accuracy: 0.9323 - val_loss: 0.3241 - val_accuracy: 0.8943\n",
      "Epoch 17/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1760 - accuracy: 0.9352 - val_loss: 0.3297 - val_accuracy: 0.8923\n",
      "Epoch 18/42\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1680 - accuracy: 0.9359 - val_loss: 0.3539 - val_accuracy: 0.8867\n",
      "Epoch 19/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1629 - accuracy: 0.9381 - val_loss: 0.3355 - val_accuracy: 0.8953\n",
      "Epoch 20/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1577 - accuracy: 0.9417 - val_loss: 0.3398 - val_accuracy: 0.8942\n",
      "Epoch 21/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1520 - accuracy: 0.9426 - val_loss: 0.3572 - val_accuracy: 0.8917\n",
      "Epoch 22/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1488 - accuracy: 0.9435 - val_loss: 0.3864 - val_accuracy: 0.8870\n",
      "Epoch 23/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1432 - accuracy: 0.9458 - val_loss: 0.3676 - val_accuracy: 0.8923\n",
      "Epoch 24/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1419 - accuracy: 0.9463 - val_loss: 0.3745 - val_accuracy: 0.8927\n",
      "Epoch 25/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1354 - accuracy: 0.9498 - val_loss: 0.3714 - val_accuracy: 0.8957\n",
      "Epoch 26/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1316 - accuracy: 0.9507 - val_loss: 0.4144 - val_accuracy: 0.8847\n",
      "Epoch 27/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1311 - accuracy: 0.9511 - val_loss: 0.4090 - val_accuracy: 0.8904\n",
      "Epoch 28/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1242 - accuracy: 0.9536 - val_loss: 0.3904 - val_accuracy: 0.8974\n",
      "Epoch 29/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1258 - accuracy: 0.9526 - val_loss: 0.3988 - val_accuracy: 0.8932\n",
      "Epoch 30/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1212 - accuracy: 0.9542 - val_loss: 0.3876 - val_accuracy: 0.8938\n",
      "Epoch 31/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1164 - accuracy: 0.9563 - val_loss: 0.4322 - val_accuracy: 0.8932\n",
      "Epoch 32/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1130 - accuracy: 0.9571 - val_loss: 0.4129 - val_accuracy: 0.8949\n",
      "Epoch 33/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1109 - accuracy: 0.9591 - val_loss: 0.4197 - val_accuracy: 0.8904\n",
      "Epoch 34/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1095 - accuracy: 0.9580 - val_loss: 0.4135 - val_accuracy: 0.8935\n",
      "Epoch 35/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1064 - accuracy: 0.9604 - val_loss: 0.4292 - val_accuracy: 0.8921\n",
      "Epoch 36/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1014 - accuracy: 0.9621 - val_loss: 0.4551 - val_accuracy: 0.8903\n",
      "Epoch 37/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1013 - accuracy: 0.9619 - val_loss: 0.4676 - val_accuracy: 0.8878\n",
      "Epoch 38/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0963 - accuracy: 0.9645 - val_loss: 0.4542 - val_accuracy: 0.8932\n",
      "Epoch 39/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9642 - val_loss: 0.4597 - val_accuracy: 0.8938\n",
      "Epoch 40/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0947 - accuracy: 0.9649 - val_loss: 0.4634 - val_accuracy: 0.8909\n",
      "Epoch 41/42\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0904 - accuracy: 0.9663 - val_loss: 0.4907 - val_accuracy: 0.8871\n",
      "Epoch 42/42\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0896 - accuracy: 0.9669 - val_loss: 0.4834 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a990f2290>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "hypermodel.fit(img_train, label_train, epochs = best_epoch, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos el hipermodelo con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5171 - accuracy: 0.8865\n",
      "[test loss, test accuracy]: [0.5170891880989075, 0.8865000009536743]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print('[test loss, test accuracy]:', eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ya aprendimos a usar Keras Tuner para justar los hiperparámetros de un modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
